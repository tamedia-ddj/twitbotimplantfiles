# Twitter Scraper, um alle Tweets zu den Implantfiles zu sammeln

**Fragestellung**: Wie entwickelt sich die Diskussion zu den Implant Files auf Twitter?

Vorgehen, um den Twitter-Scraper zu aufzusetzen, und um die Daten anschliessend lokal zu analysieren.

1. Persönlich creds im .json File ergänzen
2. Den .py Code auf einen Server spielen, und alle 30 Minuten laufen lassen.
3. .csv runter ziehen und mit dem Analyse-Notebook unter die Lupe nehmen

Interessant war vor allem, wie gut [LangDetect](https://pypi.org/project/langdetect/) funktioniert hat.

Der [publizierte Artikel](https://www.tagesanzeiger.ch/the-implant-files/29-000-tweets-mit-1500-artikellinks-in-33-sprachen/story/13508573) ist hier zu finden.
